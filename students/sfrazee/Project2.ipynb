{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step is to get the data\n",
    "We are going to rely on the Galaxy team to pull together our sequence data for now. We might change this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "from os.path import isfile\n",
    "\n",
    "FORCE_GENOME_DOWNLOAD = False\n",
    "\n",
    "url = 'https://covid19.galaxyproject.org/genomics/4-Variation/current_complete_ncov_genomes.fasta'\n",
    "file = '../../current_complete_ncov_genomes.fasta'\n",
    "\n",
    "if FORCE_GENOME_DOWNLOAD or not isfile(file):\n",
    "    wget.download(url, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virus Alignment\n",
    "Using the alignment generated by Dr. A. Will probably code to do this automatically later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the sequences into pandas so we can process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading alignment table into string dictionary\n",
      "Read alignment table in 1.2661 seconds\n",
      "Alignment table stats:\n",
      "             seqid S_1_1 S_1_2 S_1_3 S_2_1 S_2_2 S_2_3 S_3_1 S_3_2 S_3_3  ...  \\\n",
      "count          677   677   677   677   677   677   677   677   677   677  ...   \n",
      "unique         677     1     1     1     1     1     1     1     1     1  ...   \n",
      "top     MT263410.1     A     T     G     T     T     T     G     T     T  ...   \n",
      "freq             1   677   677   677   677   677   677   677   677   677  ...   \n",
      "\n",
      "       S_1270_3 S_1271_1 S_1271_2 S_1271_3 S_1272_1 S_1272_2 S_1272_3  \\\n",
      "count       677      677      677      677      677      677      677   \n",
      "unique        1        1        1        1        1        1        1   \n",
      "top           A        C        A        T        T        A        C   \n",
      "freq        677      677      677      677      677      677      677   \n",
      "\n",
      "       S_1273_1 S_1273_2 S_1273_3  \n",
      "count       677      677      677  \n",
      "unique        1        1        1  \n",
      "top           A        C        A  \n",
      "freq        677      677      677  \n",
      "\n",
      "[4 rows x 3820 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from os.path import isfile\n",
    "\n",
    "ALIGNMENT_PATH = '../../data/position_table.csv'\n",
    "\n",
    "print(\"Reading alignment table into string dictionary\")\n",
    "start = time()\n",
    "\n",
    "position_table = pd.read_csv('../../data/position_table.csv')\n",
    "\n",
    "end = time()\n",
    "print(f\"Read alignment table in {round(end-start, 4)} seconds\")\n",
    "\n",
    "print(\"Alignment table stats:\")\n",
    "results = position_table.describe()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull out the concensus sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "S_1_1       A\nS_1_2       T\nS_1_3       G\nS_2_1       T\nS_2_2       T\n           ..\nS_1272_2    A\nS_1272_3    C\nS_1273_1    A\nS_1273_2    C\nS_1273_3    A\nName: 0, Length: 3819, dtype: object"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concensus_seq = position_table.drop('seqid',axis=1).mode(axis=0).T[0]\n",
    "concensus_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort samples by distance from the concensus sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating distances from consensus sequence: 0.8187 seconds\n",
      "Sorting sequences by consensus distance: 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "position_table = position_table.set_index('seqid')\n",
    "print(\"Calculating distances from consensus sequence: \", end='')\n",
    "start = time()\n",
    "distance_from_concensus_seq = position_table.apply(lambda row: sum(row != concensus_seq),axis=1)\n",
    "end = time()\n",
    "print(f\"{round(end-start, 4)} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Sorting sequences by consensus distance: \", end='')\n",
    "start = time()\n",
    "distance_from_concensus_seq_sorted = distance_from_concensus_seq.sort_values(ascending=False)\n",
    "end = time()\n",
    "print(f\"{round(end-start, 4)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select 10 sequences to do our first analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most distant sequences from consensus\n",
      "seqid\n",
      "MT233522.1    82\n",
      "MT308696.1    71\n",
      "MT308694.1    53\n",
      "MT263453.1    48\n",
      "MT259284.1    33\n",
      "MT293180.1    24\n",
      "MT263436.1    10\n",
      "MT293224.1    10\n",
      "MT326129.1    10\n",
      "MT259277.1    10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"10 most distant sequences from consensus\")\n",
    "print(distance_from_concensus_seq_sorted[0:10])\n",
    "subset_seqs = distance_from_concensus_seq_sorted[:10].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct distance matrices for our sequences\n",
    "\n",
    "To compare the effects of using different distance algorithms to generate the distance table, I'm going to apply as many as I can find! I'm using the textdistance package since it neatly packages many of the algorithms into objects that are easily interchangeable.\n",
    "\n",
    "Not all of these algorithms are designed or even fit for RNA string distance, but I'm going to do more exploration on which of these works best later. Hopefully I can group together samples that occurred in the same region and classify which algorithms best predict that kind of closeness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Hamming distances from csv: 0.006 seconds\n",
      "Loading Levenshtein distances from csv: 0.004 seconds\n",
      "Loading DamerauLevenshtein distances from csv: 0.004 seconds\n",
      "Loading SmithWaterman distances from csv: 0.003 seconds\n",
      "Loading MLIPNS distances from csv: 0.004 seconds\n",
      "Loading JaroWinkler distances from csv: 0.004 seconds\n",
      "Calculating distances using NeedlemanWunsch algorithm: \tCalculating all distances for MT233522.1\n",
      "\tCalculating all distances for MT308696.1\n"
     ]
    }
   ],
   "source": [
    "import textdistance as td\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "from students.sfrazee.multiprocessing_helpers import get_distance_multi\n",
    "\n",
    "\n",
    "LOCAL_DATA_DIR = \"./data\"\n",
    "DISTANCE_CSV_SUFFIX = \"_distances.csv\"\n",
    "INVALID_SUFFIX = \"_distances.invalid\"\n",
    "FORCE_DISTANCE_REFRESH = False\n",
    "\n",
    "# ensure the data folder exists\n",
    "Path(LOCAL_DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# We don't want to create objects quite yet so we can get their names\n",
    "# Note: Hamming will complete relatively quickly, but other algorithms are MANY times slower\n",
    "dist_algorithms = [td.Hamming, td.Levenshtein, td.DamerauLevenshtein, td.SmithWaterman, td.MLIPNS, td.JaroWinkler, td.NeedlemanWunsch, td.Gotoh]\n",
    "\n",
    "all_distances = {}\n",
    "\n",
    "for dist_lib in dist_algorithms:\n",
    "    this_csv_path = f\"{LOCAL_DATA_DIR}/{dist_lib.__name__}{DISTANCE_CSV_SUFFIX}\"\n",
    "    this_invalid_path = f\"{LOCAL_DATA_DIR}/{dist_lib.__name__}{INVALID_SUFFIX}\"\n",
    "\n",
    "    # Only re-calculate distances if the csv doesn't exist or we want to force recalculation\n",
    "    if FORCE_DISTANCE_REFRESH or \\\n",
    "        (not Path(this_csv_path).exists() and not Path(this_invalid_path).exists()):\n",
    "        dist_alg = dist_lib()\n",
    "        print(f\"Calculating distances using {dist_lib.__name__} algorithm: \", end='')\n",
    "        distances = {}\n",
    "\n",
    "        #Use multiple processes to evaluate distances (THIS WILL MAX OUT YOUR CPU)\n",
    "        with Pool() as pool:\n",
    "\n",
    "            start = time()\n",
    "            for i,seqid1 in enumerate(subset_seqs):\n",
    "                print(f\"\\tCalculating all distances for {seqid1}\")\n",
    "\n",
    "                # use a list comprehension to set up the arguments for each function call\n",
    "                args = [[dist_alg, position_table, seqid1, seqid2] for seqid2 in subset_seqs.values]\n",
    "\n",
    "                # calculate this row of the distance table\n",
    "                results = pool.starmap(get_distance_multi, args)\n",
    "                \n",
    "                for retid1, retid2, distance in results:\n",
    "                    distances[retid1,retid2] = distance\n",
    "\n",
    "            end = time()\n",
    "        print(f\"{round(end-start, 4)} seconds\")\n",
    "\n",
    "        distances_valid = True\n",
    "        print(\"Validating distances\")\n",
    "\n",
    "        # validate symmetric property\n",
    "        for i,seqid1 in enumerate(subset_seqs):\n",
    "            for j,seqid2 in enumerate(subset_seqs):\n",
    "                if seqid1 != seqid2 and distances[seqid1,seqid2] != distances[seqid2,seqid1]:\n",
    "                    distances_valid=False\n",
    "                    print(\"Symmetric property violated\")\n",
    "                    break\n",
    "\n",
    "        # validate triangle inequality\n",
    "        if distances_valid:\n",
    "            for i,seqid_i in enumerate(subset_seqs):\n",
    "                if not distances_valid:\n",
    "                        break\n",
    "                for j,seqid_j in enumerate(subset_seqs):\n",
    "                    if not distances_valid:\n",
    "                        break\n",
    "                    for k, seqid_k in enumerate(subset_seqs):\n",
    "                        if not distances_valid:\n",
    "                            break\n",
    "                        if i != j and j != k and i != k:\n",
    "                            if distances[seqid_i,seqid_j] > distances[seqid_i, seqid_k] + distances[seqid_j, seqid_k]:\n",
    "                                distances_valid = False\n",
    "                                print(f\"Triangle inequality violated: {distances[seqid_i, seqid_k]}+{distances[seqid_j, seqid_k]}<{distances[seqid_i,seqid_j]}\")\n",
    "\n",
    "        # convert to pandas and save to csv\n",
    "        distances = pd.Series(distances).unstack()\n",
    "        if(distances_valid):\n",
    "            distances.to_csv(this_csv_path)\n",
    "            all_distances[dist_lib.__name__] = distances\n",
    "\n",
    "        else:\n",
    "            distances.to_csv(this_invalid_path)\n",
    "\n",
    "    else:\n",
    "        if Path(this_invalid_path).exists():\n",
    "            print(f\"Found {dist_lib.__name__} distances csv, but it was marked as invalid\")\n",
    "        else:\n",
    "            print(f\"Loading {dist_lib.__name__} distances from csv: \", end='')\n",
    "            start = time()\n",
    "            distances = pd.read_csv(this_csv_path, index_col=0)\n",
    "            end = time()\n",
    "            print(f\"{round(end-start, 4)} seconds\")\n",
    "            all_distances[dist_lib.__name__] = distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize biopython\n",
    "Convert from panda dataframes to distance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceMatrix\n",
    "\n",
    "all_matrices = {}\n",
    "\n",
    "for d_key, distances in all_distances.items():\n",
    "\n",
    "    matrix = pd.np.tril(distances.values).tolist()\n",
    "    for i in range(len(matrix)):\n",
    "        matrix[i] = matrix[i][:i+1]\n",
    "    dm = DistanceMatrix(list(distances.index), matrix)\n",
    "\n",
    "    all_matrices[d_key] = dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now construct and draw our trees\n",
    "(More annotation coming later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "from Bio import Phylo\n",
    "\n",
    "for dm in all_matrices.values():\n",
    "\n",
    "    constructor = DistanceTreeConstructor()\n",
    "    tree = constructor.nj(dm)\n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    tree.ladderize()   # Flip branches so deeper clades are displayed at top\n",
    "    Phylo.draw(tree)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}