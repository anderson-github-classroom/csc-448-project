{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Part 2 (a.k.a. Project 2 on Schedule)\n",
    "While you are learning about evolutionary trees and distance matrices this week in lecture/lab we can get started on pulling together the data we need for our COVID-19 analysis. We can also do some starter analysis. Our goal over the next few weeks will be to clean, refine, and otherwise make detailed, explained, reproducible analysis.\n",
    "\n",
    "The current complete genomes can be downloaded from here:\n",
    "https://covid19.galaxyproject.org/genomics/4-Variation/current_complete_ncov_genomes.fasta\n",
    "\n",
    "Disclaimers: I definitely expect for the analysis below to change. This isn't a lab. This is a first cut to get us discussing. We need to be critical of this work and look for problems and ways to improve it. We need to be skeptical scientists. We need to dig into the literature not just about the tools, but about the biology itself before putting out potentially misleading information. \n",
    "\n",
    "Technical Disclaimers: I've written this to run on my system. I want you to use this notebook as motivation and guidance to approach this weeks project. Some of the things I've done below may or may not be in your data analysis/programming/data science wheel house. That's ok. There is a lot of room for variety. Try to approach this in a genuine way about what you are interested in contributing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidance (i.e., what you should do)\n",
    "We've said many times. This project isn't about everyone reaching the same point in a predetermined set of steps. It's about applying what we are learning in class to produce real data analysis for the community. It is about as *Learn by doing* as you could possibly get at Cal Poly. So what should you be doing this week for the project? Here is some guidance (but remember this is only to guide you and not box you into specific tasks). They are in no particular order. \n",
    "* Consider what questions we want to ask from our evolutionary tree analysis. Think about what questions the book was trying to answer. Do we even have the data in this notebook to answer some of those questions? If not, spend time trying to find it now that you can know more about what to look for in terms of format. Do some literature searching and see what other work has been done for this virus and others.\n",
    "* Research and try different evolutionary tree programs/frameworks. What I've done below is not the only game in town by far. Biopython itself has different options.\n",
    "* Consider the alignment itself. Are there different ways to do this? Did we do it correctly?\n",
    "* What about the sequences themselves? Are they all of the same quality? Should we exclude some?\n",
    "* What about the virus alignment program? Did we use that correctly? Should we have done the entire sequence instead of using Spike as a reference? Should we try a different reference. \n",
    "* Do we have more data available about the sequences? Part of world, etc. Can we do some digging here to answer different questions.\n",
    "* And I'm sure you can think of more to attempt... Think about what you want to do. Spend time working towards a well thoughtout goal. Document things as you go. Talk to everyone on Slack. Together we can do this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to clone the repository\n",
    "Here is a link to the project repository.\n",
    "\n",
    "https://github.com/anderson-github-classroom/csc-448-project\n",
    "\n",
    "The website can be viewed at https://anderson-github-classroom.github.io/csc-448-project/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step is to get the data\n",
    "We are going to rely on the Galaxy team to pull together our sequence data for now. We might change this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "from os.path import isfile\n",
    "\n",
    "FORCE_GENOME_DOWNLOAD = False\n",
    "\n",
    "url = 'https://covid19.galaxyproject.org/genomics/4-Variation/current_complete_ncov_genomes.fasta'\n",
    "file = '../../current_complete_ncov_genomes.fasta'\n",
    "\n",
    "if FORCE_GENOME_DOWNLOAD or not isfile(file):\n",
    "    wget.download(url, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virus Alignment\n",
    "Using the alignment generated by Dr. A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the sequences into pandas so we can process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading alignment table into string dictionary\n",
      "Read alignment table in 1.7875 seconds\n",
      "Alignment table stats:\n",
      "             seqid S_1_1 S_1_2 S_1_3 S_2_1 S_2_2 S_2_3 S_3_1 S_3_2 S_3_3  ...  \\\n",
      "count          677   677   677   677   677   677   677   677   677   677  ...   \n",
      "unique         677     1     1     1     1     1     1     1     1     1  ...   \n",
      "top     MT259261.1     A     T     G     T     T     T     G     T     T  ...   \n",
      "freq             1   677   677   677   677   677   677   677   677   677  ...   \n",
      "\n",
      "       S_1270_3 S_1271_1 S_1271_2 S_1271_3 S_1272_1 S_1272_2 S_1272_3  \\\n",
      "count       677      677      677      677      677      677      677   \n",
      "unique        1        1        1        1        1        1        1   \n",
      "top           A        C        A        T        T        A        C   \n",
      "freq        677      677      677      677      677      677      677   \n",
      "\n",
      "       S_1273_1 S_1273_2 S_1273_3  \n",
      "count       677      677      677  \n",
      "unique        1        1        1  \n",
      "top           A        C        A  \n",
      "freq        677      677      677  \n",
      "\n",
      "[4 rows x 3820 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from os.path import isfile\n",
    "\n",
    "ALIGNMENT_PATH = '../../data/position_table.csv'\n",
    "\n",
    "print(\"Reading alignment table into string dictionary\")\n",
    "start = time()\n",
    "\n",
    "position_table = pd.read_csv('../../data/position_table.csv')\n",
    "\n",
    "end = time()\n",
    "print(f\"Read alignment table in {round(end-start, 4)} seconds\")\n",
    "\n",
    "print(\"Alignment table stats:\")\n",
    "results = position_table.describe()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull out the concensus sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "S_1_1       A\nS_1_2       T\nS_1_3       G\nS_2_1       T\nS_2_2       T\n           ..\nS_1272_2    A\nS_1272_3    C\nS_1273_1    A\nS_1273_2    C\nS_1273_3    A\nName: 0, Length: 3819, dtype: object"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concensus_seq = position_table.drop('seqid',axis=1).mode(axis=0).T[0]\n",
    "concensus_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort samples by distance from the concensus sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating distances from consensus sequence: 1.0399 seconds\n",
      "Sorting sequences by consensus distance: 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "position_table = position_table.set_index('seqid')\n",
    "print(\"Calculating distances from consensus sequence: \", end='')\n",
    "start = time()\n",
    "distance_from_concensus_seq = position_table.apply(lambda row: sum(row != concensus_seq),axis=1)\n",
    "end = time()\n",
    "print(f\"{round(end-start, 4)} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Sorting sequences by consensus distance: \", end='')\n",
    "start = time()\n",
    "distance_from_concensus_seq_sorted = distance_from_concensus_seq.sort_values(ascending=False)\n",
    "end = time()\n",
    "print(f\"{round(end-start, 4)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select 10 sequences to do our first analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most distant sequences from consensus\n",
      "seqid\n",
      "MT233522.1    82\n",
      "MT308696.1    71\n",
      "MT308694.1    53\n",
      "MT263453.1    48\n",
      "MT259284.1    33\n",
      "MT293180.1    24\n",
      "MT263436.1    10\n",
      "MT293224.1    10\n",
      "MT326129.1    10\n",
      "MT259277.1    10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"10 most distant sequences from consensus\")\n",
    "print(distance_from_concensus_seq_sorted[0:10])\n",
    "subset_seqs = distance_from_concensus_seq_sorted[:10].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct distance matrices for our sequences\n",
    "\n",
    "To compare the effects of using different distance algorithms to generate the distance table, I'm going to apply as many as I can find! I'm using the textdistance package since it neatly packages many of the algorithms into objects that are easily interchangeable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Hamming distances from csv: 0.006 seconds\n",
      "Loading Levenshtein distances from csv: 0.0029 seconds\n",
      "Loading DamerauLevenshtein distances from csv: 0.004 seconds\n"
     ]
    }
   ],
   "source": [
    "import textdistance as td\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "LOCAL_DATA_DIR = \"./data\"\n",
    "DISTANCE_CSV_SUFFIX = \"_distances.csv\"\n",
    "INVALID_SUFFIX = \"_distances.invalid\"\n",
    "FORCE_DISTANCE_REFRESH = False\n",
    "\n",
    "# ensure the data folder exists\n",
    "Path(LOCAL_DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# We don't want to create objects quite yet so we can get their names\n",
    "# Note: Hamming will complete relatively quickly, but other algorithms are MANY times slower\n",
    "dist_algorithms = [td.Hamming, td.Levenshtein, td.DamerauLevenshtein]\n",
    "\n",
    "all_distances = {}\n",
    "\n",
    "for dist_lib in dist_algorithms:\n",
    "    this_csv_path = f\"{LOCAL_DATA_DIR}/{dist_lib.__name__}{DISTANCE_CSV_SUFFIX}\"\n",
    "    this_invalid_path = f\"{LOCAL_DATA_DIR}/{dist_lib.__name__}{INVALID_SUFFIX}\"\n",
    "\n",
    "    # Only re-calculate distances if the csv doesn't exist or we want to force recalculation\n",
    "    if FORCE_DISTANCE_REFRESH or \\\n",
    "        (not Path(this_csv_path).exists() and not Path(this_invalid_path).exists()):\n",
    "        dist_alg = dist_lib()\n",
    "        print(f\"Calculating distances using {dist_lib.__name__} algorithm: \", end='')\n",
    "        distances = {}\n",
    "        start = time()\n",
    "        for i,seqid1 in enumerate(subset_seqs):\n",
    "            for j in range(len(subset_seqs)):\n",
    "                seqid2 = subset_seqs[j]\n",
    "\n",
    "                if seqid1 == seqid2:\n",
    "                    distances[seqid1,seqid2]=0\n",
    "                else:\n",
    "                    distances[seqid1,seqid2] = dist_alg.distance(list(position_table.loc[seqid1]),\n",
    "                                                                 list(position_table.loc[seqid2]))\n",
    "\n",
    "        end = time()\n",
    "        print(f\"{round(end-start, 4)} seconds\")\n",
    "\n",
    "        distances_valid = True\n",
    "        print(\"Validating distances\")\n",
    "\n",
    "        # validate symmetric property\n",
    "        for i,seqid1 in enumerate(subset_seqs):\n",
    "            for j,seqid2 in enumerate(subset_seqs):\n",
    "                if seqid1 != seqid2 and distances[seqid1,seqid2] != distances[seqid2,seqid1]:\n",
    "                    distances_valid=False\n",
    "                    print(\"Symmetric property violated\")\n",
    "                    break\n",
    "\n",
    "        # validate triangle inequality\n",
    "        if distances_valid:\n",
    "            for i,seqid_i in enumerate(subset_seqs):\n",
    "                if not distances_valid:\n",
    "                        break\n",
    "                for j,seqid_j in enumerate(subset_seqs):\n",
    "                    if not distances_valid:\n",
    "                        break\n",
    "                    for k, seqid_k in enumerate(subset_seqs):\n",
    "                        if not distances_valid:\n",
    "                            break\n",
    "                        if i != j and j != k and i != k:\n",
    "                            if distances[seqid_i,seqid_j] > distances[seqid_i, seqid_k] + distances[seqid_j, seqid_k]:\n",
    "                                distances_valid = False\n",
    "                                print(f\"Triangle inequality violated: {distances[seqid_i, seqid_k]}+{distances[seqid_j, seqid_k]}<{distances[seqid_i,seqid_j]}\")\n",
    "\n",
    "        # convert to pandas and save to csv\n",
    "        distances = pd.Series(distances).unstack()\n",
    "        if(distances_valid):\n",
    "            distances.to_csv(this_csv_path)\n",
    "            all_distances[dist_lib.__name__] = distances\n",
    "\n",
    "        else:\n",
    "            distances.to_csv(this_invalid_path)\n",
    "\n",
    "    else:\n",
    "        if Path(this_invalid_path).exists():\n",
    "            print(f\"Found {dist_lib.__name__} distances csv, but it was marked as invalid\")\n",
    "        else:\n",
    "            print(f\"Loading {dist_lib.__name__} distances from csv: \", end='')\n",
    "            start = time()\n",
    "            distances = pd.read_csv(this_csv_path, index_col=0)\n",
    "            end = time()\n",
    "            print(f\"{round(end-start, 4)} seconds\")\n",
    "            all_distances[dist_lib.__name__] = distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize biopython\n",
    "For this analysis we'll use a package called biopython: ``pip install biopython``. \n",
    "\n",
    "It has its own formats, so we'll need to convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  90 115  90 130 104  90 135 151  90]\n",
      " [ 90   0  43   2  58  32   2  63  79   0]\n",
      " [115  43   0  43  81  47  43  86 104  43]\n",
      " [ 90   2  43   0  58  32   0  63  79   2]\n",
      " [130  58  81  58   0  68  58 101 119  58]\n",
      " [104  32  47  32  68   0  32  77  93  32]\n",
      " [ 90   2  43   0  58  32   0  63  79   2]\n",
      " [135  63  86  63 101  77  63   0  22  63]\n",
      " [151  79 104  79 119  93  79  22   0  79]\n",
      " [ 90   0  43   2  58  32   2  63  79   0]]\n",
      "[[  0  90 115  90 130 104  90 135 151  90]\n",
      " [ 90   0  43   2  58  32   2  63  79   0]\n",
      " [115  43   0  43  81  47  43  86 104  43]\n",
      " [ 90   2  43   0  58  32   0  63  79   2]\n",
      " [130  58  81  58   0  68  58 101 119  58]\n",
      " [104  32  47  32  68   0  32  77  93  32]\n",
      " [ 90   2  43   0  58  32   0  63  79   2]\n",
      " [135  63  86  63 101  77  63   0  22  63]\n",
      " [151  79 104  79 119  93  79  22   0  79]\n",
      " [ 90   0  43   2  58  32   2  63  79   0]]\n",
      "[[  0  90 115  90 130 104  90 135 151  90]\n",
      " [ 90   0  43   2  58  32   2  63  79   0]\n",
      " [115  43   0  43  81  47  43  86 104  43]\n",
      " [ 90   2  43   0  58  32   0  63  79   2]\n",
      " [130  58  81  58   0  68  58 101 119  58]\n",
      " [104  32  47  32  68   0  32  77  93  32]\n",
      " [ 90   2  43   0  58  32   0  63  79   2]\n",
      " [135  63  86  63 101  77  63   0  22  63]\n",
      " [151  79 104  79 119  93  79  22   0  79]\n",
      " [ 90   0  43   2  58  32   2  63  79   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sfrazee\\.virtualenvs\\csc-448-project-nhuursrk\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceMatrix\n",
    "\n",
    "all_matrices = {}\n",
    "\n",
    "for d_key, distances in all_distances.items():\n",
    "    \n",
    "    matrix = pd.np.tril(distances.values).tolist()\n",
    "    for i in range(len(matrix)):\n",
    "        matrix[i] = matrix[i][:i+1]\n",
    "    dm = DistanceMatrix(list(distances.index), matrix)\n",
    "\n",
    "    all_matrices[d_key] = dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now construct our tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "constructor = DistanceTreeConstructor()\n",
    "tree = constructor.nj(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now draw our tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-76-44deb93a106b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mget_ipython\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'matplotlib'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'inline'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mBio\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPhylo\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mladderize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m   \u001B[1;31m# Flip branches so deeper clades are displayed at top\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mPhylo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtree\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\sfrazee\\.virtualenvs\\csc-448-project-nhuursrk\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mrun_line_magic\u001B[1;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[0;32m   2315\u001B[0m                 \u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'local_ns'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getframe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstack_depth\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf_locals\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2316\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuiltin_trap\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2317\u001B[1;33m                 \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2318\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2319\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<decorator-gen-109>\u001B[0m in \u001B[0;36mmatplotlib\u001B[1;34m(self, line)\u001B[0m\n",
      "\u001B[1;32mc:\\users\\sfrazee\\.virtualenvs\\csc-448-project-nhuursrk\\lib\\site-packages\\IPython\\core\\magic.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(f, *a, **k)\u001B[0m\n\u001B[0;32m    185\u001B[0m     \u001B[1;31m# but it's overkill for just that one bit of state.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    186\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mmagic_deco\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 187\u001B[1;33m         \u001B[0mcall\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mlambda\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    188\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    189\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\sfrazee\\.virtualenvs\\csc-448-project-nhuursrk\\lib\\site-packages\\IPython\\core\\magics\\pylab.py\u001B[0m in \u001B[0;36mmatplotlib\u001B[1;34m(self, line)\u001B[0m\n\u001B[0;32m     97\u001B[0m             \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Available matplotlib backends: %s\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mbackends_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 99\u001B[1;33m             \u001B[0mgui\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbackend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshell\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menable_matplotlib\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgui\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgui\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgui\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    100\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_show_matplotlib_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgui\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\sfrazee\\.virtualenvs\\csc-448-project-nhuursrk\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36menable_matplotlib\u001B[1;34m(self, gui)\u001B[0m\n\u001B[0;32m   3405\u001B[0m         \"\"\"\n\u001B[0;32m   3406\u001B[0m         \u001B[1;32mfrom\u001B[0m \u001B[0mIPython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpylabtools\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3407\u001B[1;33m         \u001B[0mgui\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbackend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfind_gui_and_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgui\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpylab_gui_select\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3408\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3409\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mgui\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m'inline'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\sfrazee\\.virtualenvs\\csc-448-project-nhuursrk\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001B[0m in \u001B[0;36mfind_gui_and_backend\u001B[1;34m(gui, gui_select)\u001B[0m\n\u001B[0;32m    278\u001B[0m     \"\"\"\n\u001B[0;32m    279\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 280\u001B[1;33m     \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    281\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    282\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mgui\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mgui\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m'auto'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from Bio import Phylo\n",
    "tree.ladderize()   # Flip branches so deeper clades are displayed at top\n",
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please see the guidance at the top of the page for what to try**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}