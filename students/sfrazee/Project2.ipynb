{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Part 2 (a.k.a. Project 2 on Schedule)\n",
    "While you are learning about evolutionary trees and distance matrices this week in lecture/lab we can get started on pulling together the data we need for our COVID-19 analysis. We can also do some starter analysis. Our goal over the next few weeks will be to clean, refine, and otherwise make detailed, explained, reproducible analysis.\n",
    "\n",
    "The current complete genomes can be downloaded from here:\n",
    "https://covid19.galaxyproject.org/genomics/4-Variation/current_complete_ncov_genomes.fasta\n",
    "\n",
    "Disclaimers: I definitely expect for the analysis below to change. This isn't a lab. This is a first cut to get us discussing. We need to be critical of this work and look for problems and ways to improve it. We need to be skeptical scientists. We need to dig into the literature not just about the tools, but about the biology itself before putting out potentially misleading information. \n",
    "\n",
    "Technical Disclaimers: I've written this to run on my system. I want you to use this notebook as motivation and guidance to approach this weeks project. Some of the things I've done below may or may not be in your data analysis/programming/data science wheel house. That's ok. There is a lot of room for variety. Try to approach this in a genuine way about what you are interested in contributing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidance (i.e., what you should do)\n",
    "We've said many times. This project isn't about everyone reaching the same point in a predetermined set of steps. It's about applying what we are learning in class to produce real data analysis for the community. It is about as *Learn by doing* as you could possibly get at Cal Poly. So what should you be doing this week for the project? Here is some guidance (but remember this is only to guide you and not box you into specific tasks). They are in no particular order. \n",
    "* Consider what questions we want to ask from our evolutionary tree analysis. Think about what questions the book was trying to answer. Do we even have the data in this notebook to answer some of those questions? If not, spend time trying to find it now that you can know more about what to look for in terms of format. Do some literature searching and see what other work has been done for this virus and others.\n",
    "* Research and try different evolutionary tree programs/frameworks. What I've done below is not the only game in town by far. Biopython itself has different options.\n",
    "* Consider the alignment itself. Are there different ways to do this? Did we do it correctly?\n",
    "* What about the sequences themselves? Are they all of the same quality? Should we exclude some?\n",
    "* What about the virus alignment program? Did we use that correctly? Should we have done the entire sequence instead of using Spike as a reference? Should we try a different reference. \n",
    "* Do we have more data available about the sequences? Part of world, etc. Can we do some digging here to answer different questions.\n",
    "* And I'm sure you can think of more to attempt... Think about what you want to do. Spend time working towards a well thoughtout goal. Document things as you go. Talk to everyone on Slack. Together we can do this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to clone the repository\n",
    "Here is a link to the project repository.\n",
    "\n",
    "https://github.com/anderson-github-classroom/csc-448-project\n",
    "\n",
    "The website can be viewed at https://anderson-github-classroom.github.io/csc-448-project/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step is to get the data\n",
    "We are going to rely on the Galaxy team to pull together our sequence data for now. We might change this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "from os.path import isfile\n",
    "\n",
    "FORCE_GENOME_DOWNLOAD = False\n",
    "\n",
    "url = 'https://covid19.galaxyproject.org/genomics/4-Variation/current_complete_ncov_genomes.fasta'\n",
    "file = '../../current_complete_ncov_genomes.fasta'\n",
    "\n",
    "if FORCE_GENOME_DOWNLOAD or not isfile(file):\n",
    "    wget.download(url, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virus Alignment\n",
    "Using the alignment generated by Dr. A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the sequences into pandas so we can process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading alignment table into string dictionary\n",
      "Read alignment table in 1.1814 seconds\n",
      "Alignment table stats:\n",
      "             seqid S_1_1 S_1_2 S_1_3 S_2_1 S_2_2 S_2_3 S_3_1 S_3_2 S_3_3  ...  \\\n",
      "count          677   677   677   677   677   677   677   677   677   677  ...   \n",
      "unique         677     1     1     1     1     1     1     1     1     1  ...   \n",
      "top     MT325629.1     A     T     G     T     T     T     G     T     T  ...   \n",
      "freq             1   677   677   677   677   677   677   677   677   677  ...   \n",
      "\n",
      "       S_1270_3 S_1271_1 S_1271_2 S_1271_3 S_1272_1 S_1272_2 S_1272_3  \\\n",
      "count       677      677      677      677      677      677      677   \n",
      "unique        1        1        1        1        1        1        1   \n",
      "top           A        C        A        T        T        A        C   \n",
      "freq        677      677      677      677      677      677      677   \n",
      "\n",
      "       S_1273_1 S_1273_2 S_1273_3  \n",
      "count       677      677      677  \n",
      "unique        1        1        1  \n",
      "top           A        C        A  \n",
      "freq        677      677      677  \n",
      "\n",
      "[4 rows x 3820 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from os.path import isfile\n",
    "\n",
    "ALIGNMENT_PATH = '../../data/position_table.csv'\n",
    "\n",
    "print(\"Reading alignment table into string dictionary\")\n",
    "start = time()\n",
    "\n",
    "position_table = pd.read_csv('../../data/position_table.csv')\n",
    "\n",
    "end = time()\n",
    "print(f\"Read alignment table in {round(end-start, 4)} seconds\")\n",
    "\n",
    "print(\"Alignment table stats:\")\n",
    "results = position_table.describe()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull out the concensus sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "S_1_1       A\nS_1_2       T\nS_1_3       G\nS_2_1       T\nS_2_2       T\n           ..\nS_1272_2    A\nS_1272_3    C\nS_1273_1    A\nS_1273_2    C\nS_1273_3    A\nName: 0, Length: 3819, dtype: object"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concensus_seq = position_table.drop('seqid',axis=1).mode(axis=0).T[0]\n",
    "concensus_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort samples by distance from the concensus sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating distances from consensus sequence: 0.832 seconds\n",
      "Sorting sequences by consensus distance: 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "position_table = position_table.set_index('seqid')\n",
    "print(\"Calculating distances from consensus sequence: \", end='')\n",
    "start = time()\n",
    "distance_from_concensus_seq = position_table.apply(lambda row: sum(row != concensus_seq),axis=1)\n",
    "end = time()\n",
    "print(f\"{round(end-start, 4)} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Sorting sequences by consensus distance: \", end='')\n",
    "start = time()\n",
    "distance_from_concensus_seq_sorted = distance_from_concensus_seq.sort_values(ascending=False)\n",
    "end = time()\n",
    "print(f\"{round(end-start, 4)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select 10 sequences to do our first analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most distant sequences from consensus\n",
      "seqid\n",
      "MT233522.1    82\n",
      "MT308696.1    71\n",
      "MT308694.1    53\n",
      "MT263453.1    48\n",
      "MT259284.1    33\n",
      "MT293180.1    24\n",
      "MT263436.1    10\n",
      "MT293224.1    10\n",
      "MT326129.1    10\n",
      "MT259277.1    10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"10 most distant sequences from consensus\")\n",
    "print(distance_from_concensus_seq_sorted[0:10])\n",
    "subset_seqs = distance_from_concensus_seq_sorted[:10].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct distance matrices for our sequences\n",
    "\n",
    "To compare the effects of using different distance algorithms to generate the distance table, I'm going to apply as many as I can find! I'm using the textdistance package since it neatly packages many of the algorithms into objects that are easily interchangeable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating distances using Hamming algorithm: 0.1057 seconds\n",
      "       MT233522.1  MT259277.1  MT259284.1  MT263436.1  MT263453.1  MT293180.1  \\\n",
      "count   10.000000   10.000000   10.000000   10.000000   10.000000   10.000000   \n",
      "mean    99.500000   36.900000   60.500000   36.900000   73.100000   51.700000   \n",
      "std     41.317873   34.863065   34.961089   34.863065   37.218424   32.649826   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     90.000000    2.000000   43.000000    2.000000   58.000000   32.000000   \n",
      "50%     97.000000   37.500000   45.000000   37.500000   63.000000   39.500000   \n",
      "75%    126.250000   61.750000   84.750000   61.750000   96.000000   74.750000   \n",
      "max    151.000000   90.000000  115.000000   90.000000  130.000000  104.000000   \n",
      "\n",
      "       MT293224.1  MT308694.1  MT308696.1  MT326129.1  \n",
      "count   10.000000   10.000000   10.000000   10.000000  \n",
      "mean    36.900000   67.300000   80.500000   36.900000  \n",
      "std     34.863065   37.739016   43.553926   34.863065  \n",
      "min      0.000000    0.000000    0.000000    0.000000  \n",
      "25%      2.000000   63.000000   79.000000    2.000000  \n",
      "50%     37.500000   63.000000   79.000000   37.500000  \n",
      "75%     61.750000   83.750000  101.250000   61.750000  \n",
      "max     90.000000  135.000000  151.000000   90.000000  \n",
      "Calculating distances using Levenshtein algorithm: "
     ]
    }
   ],
   "source": [
    "import textdistance as td\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "LOCAL_DATA_DIR = \"./data\"\n",
    "DISTANCE_CSV_SUFFIX = \"_distances.csv\"\n",
    "FORCE_DISTANCE_REFRESH = False\n",
    "\n",
    "# ensure the data folder exists\n",
    "Path(LOCAL_DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# We don't want to create objects quite yet so we can get their names\n",
    "# Note: Hamming will complete relatively quickly, but other algorithms are MANY times slower\n",
    "dist_algorithms = [td.Hamming, td.Levenshtein]\n",
    "\n",
    "all_distances = {}\n",
    "\n",
    "for dist_lib in dist_algorithms:\n",
    "    this_csv_path = f\"{LOCAL_DATA_DIR}/{dist_lib.__name__}{DISTANCE_CSV_SUFFIX}\"\n",
    "\n",
    "    # Only re-calculate distances if the csv doesn't exist or we want to force recalculation\n",
    "    if FORCE_DISTANCE_REFRESH or not Path(this_csv_path).exists():\n",
    "        dist_alg = dist_lib()\n",
    "        print(f\"Calculating distances using {dist_lib.__name__} algorithm: \", end='')\n",
    "        distances = {}\n",
    "        start = time()\n",
    "        for i,seqid1 in enumerate(subset_seqs):\n",
    "            distances[seqid1,seqid1]=0\n",
    "            for j in range(i+1,len(subset_seqs)):\n",
    "                seqid2 = subset_seqs[j]\n",
    "                distances[seqid1,seqid2] = dist_alg.distance(list(position_table.loc[seqid1]), list(position_table.loc[seqid2]))\n",
    "                distances[seqid2,seqid1] = distances[seqid1,seqid2]\n",
    "        end = time()\n",
    "        print(f\"{round(end-start, 4)} seconds\")\n",
    "        distances = pd.Series(distances).unstack()\n",
    "        distances.to_csv(this_csv_path)\n",
    "        print(distances.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize biopython\n",
    "For this analysis we'll use a package called biopython: ``pip install biopython``. \n",
    "\n",
    "It has its own formats, so we'll need to convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceMatrix\n",
    "matrix = np.tril(distances.values).tolist()\n",
    "for i in range(len(matrix)):\n",
    "    matrix[i] = matrix[i][:i+1]\n",
    "dm = DistanceMatrix(list(distances.index), matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now construct our tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "constructor = DistanceTreeConstructor()\n",
    "tree = constructor.nj(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now draw our tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from Bio import Phylo\n",
    "tree.ladderize()   # Flip branches so deeper clades are displayed at top\n",
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please see the guidance at the top of the page for what to try**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}