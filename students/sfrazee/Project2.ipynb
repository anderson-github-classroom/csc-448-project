{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Part 2 (a.k.a. Project 2 on Schedule)\n",
    "While you are learning about evolutionary trees and distance matrices this week in lecture/lab we can get started on pulling together the data we need for our COVID-19 analysis. We can also do some starter analysis. Our goal over the next few weeks will be to clean, refine, and otherwise make detailed, explained, reproducible analysis.\n",
    "\n",
    "The current complete genomes can be downloaded from here:\n",
    "https://covid19.galaxyproject.org/genomics/4-Variation/current_complete_ncov_genomes.fasta\n",
    "\n",
    "Disclaimers: I definitely expect for the analysis below to change. This isn't a lab. This is a first cut to get us discussing. We need to be critical of this work and look for problems and ways to improve it. We need to be skeptical scientists. We need to dig into the literature not just about the tools, but about the biology itself before putting out potentially misleading information. \n",
    "\n",
    "Technical Disclaimers: I've written this to run on my system. I want you to use this notebook as motivation and guidance to approach this weeks project. Some of the things I've done below may or may not be in your data analysis/programming/data science wheel house. That's ok. There is a lot of room for variety. Try to approach this in a genuine way about what you are interested in contributing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidance (i.e., what you should do)\n",
    "We've said many times. This project isn't about everyone reaching the same point in a predetermined set of steps. It's about applying what we are learning in class to produce real data analysis for the community. It is about as *Learn by doing* as you could possibly get at Cal Poly. So what should you be doing this week for the project? Here is some guidance (but remember this is only to guide you and not box you into specific tasks). They are in no particular order. \n",
    "* Consider what questions we want to ask from our evolutionary tree analysis. Think about what questions the book was trying to answer. Do we even have the data in this notebook to answer some of those questions? If not, spend time trying to find it now that you can know more about what to look for in terms of format. Do some literature searching and see what other work has been done for this virus and others.\n",
    "* Research and try different evolutionary tree programs/frameworks. What I've done below is not the only game in town by far. Biopython itself has different options.\n",
    "* Consider the alignment itself. Are there different ways to do this? Did we do it correctly?\n",
    "* What about the sequences themselves? Are they all of the same quality? Should we exclude some?\n",
    "* What about the virus alignment program? Did we use that correctly? Should we have done the entire sequence instead of using Spike as a reference? Should we try a different reference. \n",
    "* Do we have more data available about the sequences? Part of world, etc. Can we do some digging here to answer different questions.\n",
    "* And I'm sure you can think of more to attempt... Think about what you want to do. Spend time working towards a well thoughtout goal. Document things as you go. Talk to everyone on Slack. Together we can do this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to clone the repository\n",
    "Here is a link to the project repository.\n",
    "\n",
    "https://github.com/anderson-github-classroom/csc-448-project\n",
    "\n",
    "The website can be viewed at https://anderson-github-classroom.github.io/csc-448-project/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step is to get the data\n",
    "We are going to rely on the Galaxy team to pull together our sequence data for now. We might change this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "from os.path import isfile\n",
    "\n",
    "FORCE_GENOME_DOWNLOAD = False\n",
    "\n",
    "url = 'https://covid19.galaxyproject.org/genomics/4-Variation/current_complete_ncov_genomes.fasta'\n",
    "file = '../../current_complete_ncov_genomes.fasta'\n",
    "\n",
    "if FORCE_GENOME_DOWNLOAD or not isfile(file):\n",
    "    wget.download(url, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virus Alignment\n",
    "Using the alignment generated by Dr. A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the sequences into pandas so we can process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from os.path import isfile\n",
    "\n",
    "ALIGNMENT_PATH = '../../data/position_table.csv'\n",
    "\n",
    "print(\"Reading alignment table into string dictionary\")\n",
    "start = time()\n",
    "\n",
    "position_table = pd.read_csv('../../data/position_table.csv')\n",
    "\n",
    "end = time()\n",
    "print(f\"Read alignment table in {round(end-start, 4)} seconds\")\n",
    "\n",
    "print(\"Alignment table stats:\")\n",
    "results = position_table.describe()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull out the concensus sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "concensus_seq = position_table.drop('seqid',axis=1).mode(axis=0).T[0]\n",
    "concensus_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort samples by distance from the concensus sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "position_table = position_table.set_index('seqid')\n",
    "print(\"Calculating distances from consensus sequence: \", end='')\n",
    "start = time()\n",
    "distance_from_concensus_seq = position_table.apply(lambda row: sum(row != concensus_seq),axis=1)\n",
    "end = time()\n",
    "print(f\"{round(end-start, 4)} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Sorting sequences by consensus distance: \", end='')\n",
    "start = time()\n",
    "distance_from_concensus_seq_sorted = distance_from_concensus_seq.sort_values(ascending=False)\n",
    "end = time()\n",
    "print(f\"{round(end-start, 4)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select 10 sequences to do our first analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"10 most distant sequences from consensus\")\n",
    "print(distance_from_concensus_seq_sorted[0:10])\n",
    "subset_seqs = distance_from_concensus_seq_sorted[:10].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct distance matrices for our sequences\n",
    "\n",
    "To compare the effects of using different distance algorithms to generate the distance table, I'm going to apply as many as I can find! I'm using the textdistance package since it neatly packages many of the algorithms into objects that are easily interchangeable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import textdistance as td\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "from students.sfrazee.multiprocessing_helpers import get_distance_multi\n",
    "\n",
    "\n",
    "LOCAL_DATA_DIR = \"./data\"\n",
    "DISTANCE_CSV_SUFFIX = \"_distances.csv\"\n",
    "INVALID_SUFFIX = \"_distances.invalid\"\n",
    "FORCE_DISTANCE_REFRESH = False\n",
    "\n",
    "# ensure the data folder exists\n",
    "Path(LOCAL_DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# We don't want to create objects quite yet so we can get their names\n",
    "# Note: Hamming will complete relatively quickly, but other algorithms are MANY times slower\n",
    "dist_algorithms = [td.Hamming, td.Levenshtein, td.DamerauLevenshtein, td.SmithWaterman, td.MLIPNS, td.JaroWinkler, td.StrCmp95, td.NeedlemanWunsch]\n",
    "\n",
    "all_distances = {}\n",
    "\n",
    "for dist_lib in dist_algorithms:\n",
    "    this_csv_path = f\"{LOCAL_DATA_DIR}/{dist_lib.__name__}{DISTANCE_CSV_SUFFIX}\"\n",
    "    this_invalid_path = f\"{LOCAL_DATA_DIR}/{dist_lib.__name__}{INVALID_SUFFIX}\"\n",
    "\n",
    "    # Only re-calculate distances if the csv doesn't exist or we want to force recalculation\n",
    "    if FORCE_DISTANCE_REFRESH or \\\n",
    "        (not Path(this_csv_path).exists() and not Path(this_invalid_path).exists()):\n",
    "        dist_alg = dist_lib()\n",
    "        print(f\"Calculating distances using {dist_lib.__name__} algorithm: \", end='')\n",
    "        distances = {}\n",
    "\n",
    "        #Use multiple processes to evaluate distances\n",
    "        with Pool() as pool:\n",
    "\n",
    "            start = time()\n",
    "            for i,seqid1 in enumerate(subset_seqs):\n",
    "                print(f\"\\tCalculating all distances for {seqid1}\")\n",
    "\n",
    "                # for j in range(len(subset_seqs)):\n",
    "                #     seqid2 = subset_seqs[j]\n",
    "                args = [[dist_alg, position_table, seqid1, seqid2] for seqid2 in subset_seqs.values]\n",
    "\n",
    "                results = pool.starmap(get_distance_multi, args)\n",
    "                \n",
    "                for retid1, retid2, distance in results:\n",
    "                    distances[retid1,retid2] = distance\n",
    "\n",
    "            end = time()\n",
    "        print(f\"{round(end-start, 4)} seconds\")\n",
    "\n",
    "        distances_valid = True\n",
    "        print(\"Validating distances\")\n",
    "\n",
    "        # validate symmetric property\n",
    "        for i,seqid1 in enumerate(subset_seqs):\n",
    "            for j,seqid2 in enumerate(subset_seqs):\n",
    "                if seqid1 != seqid2 and distances[seqid1,seqid2] != distances[seqid2,seqid1]:\n",
    "                    distances_valid=False\n",
    "                    print(\"Symmetric property violated\")\n",
    "                    break\n",
    "\n",
    "        # validate triangle inequality\n",
    "        if distances_valid:\n",
    "            for i,seqid_i in enumerate(subset_seqs):\n",
    "                if not distances_valid:\n",
    "                        break\n",
    "                for j,seqid_j in enumerate(subset_seqs):\n",
    "                    if not distances_valid:\n",
    "                        break\n",
    "                    for k, seqid_k in enumerate(subset_seqs):\n",
    "                        if not distances_valid:\n",
    "                            break\n",
    "                        if i != j and j != k and i != k:\n",
    "                            if distances[seqid_i,seqid_j] > distances[seqid_i, seqid_k] + distances[seqid_j, seqid_k]:\n",
    "                                distances_valid = False\n",
    "                                print(f\"Triangle inequality violated: {distances[seqid_i, seqid_k]}+{distances[seqid_j, seqid_k]}<{distances[seqid_i,seqid_j]}\")\n",
    "\n",
    "        # convert to pandas and save to csv\n",
    "        distances = pd.Series(distances).unstack()\n",
    "        if(distances_valid):\n",
    "            distances.to_csv(this_csv_path)\n",
    "            all_distances[dist_lib.__name__] = distances\n",
    "\n",
    "        else:\n",
    "            distances.to_csv(this_invalid_path)\n",
    "\n",
    "    else:\n",
    "        if Path(this_invalid_path).exists():\n",
    "            print(f\"Found {dist_lib.__name__} distances csv, but it was marked as invalid\")\n",
    "        else:\n",
    "            print(f\"Loading {dist_lib.__name__} distances from csv: \", end='')\n",
    "            start = time()\n",
    "            distances = pd.read_csv(this_csv_path, index_col=0)\n",
    "            end = time()\n",
    "            print(f\"{round(end-start, 4)} seconds\")\n",
    "            all_distances[dist_lib.__name__] = distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize biopython\n",
    "For this analysis we'll use a package called biopython: ``pip install biopython``. \n",
    "\n",
    "It has its own formats, so we'll need to convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceMatrix\n",
    "\n",
    "all_matrices = {}\n",
    "\n",
    "for d_key, distances in all_distances.items():\n",
    "\n",
    "    matrix = pd.np.tril(distances.values).tolist()\n",
    "    for i in range(len(matrix)):\n",
    "        matrix[i] = matrix[i][:i+1]\n",
    "    dm = DistanceMatrix(list(distances.index), matrix)\n",
    "\n",
    "    all_matrices[d_key] = dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now construct and draw our tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "from Bio import Phylo\n",
    "\n",
    "for dm in all_matrices.values():\n",
    "\n",
    "    constructor = DistanceTreeConstructor()\n",
    "    tree = constructor.nj(dm)\n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    tree.ladderize()   # Flip branches so deeper clades are displayed at top\n",
    "    Phylo.draw(tree)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}