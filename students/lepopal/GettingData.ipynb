{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemar Popal\n",
    "\n",
    "## Week 1\n",
    "My goal this week was to do some research on the various resources already out there on/about COVID-19 (the coronavirus). By researching what people have done already I can hopefully come up with ideas I can research and implement myself and be able to contribute meaningfully to the scientific community. \n",
    "\n",
    "---\n",
    "\n",
    "[https://www.ncbi.nlm.nih.gov/genbank/sars-cov-2-seqs/](https://www.ncbi.nlm.nih.gov/genbank/sars-cov-2-seqs/)\n",
    "\n",
    "Here’s a database of nucleotide sequences of COVID-19 collected at different dates throughout the world. I think this might be useful to see how the virus has mutated over time, and possibly see which or how many variations of the virus there were at any given time. \n",
    "\n",
    "---\n",
    "\n",
    "[biopython.org](biopython.org)\n",
    "\n",
    "This looks like one of the best Python libraries out there for biology. It seems like it includes a lot of useful tools, but most of them I don’t know to use (yet!). Using it I was able to relatively easily download all genome sequences from the NCBI database into Sequence objects in Biopython. From there we can do a lot of things, like finding the reverse complement using the built in method in the Sequence object. \n",
    "\n",
    "---\n",
    "\n",
    "[gisaid.org](https://www.gisaid.org/)\n",
    "\n",
    "This site also looks like it will be useful in my research. They make it easy for scientists to share information about virus sequences, clinical/epidemiological data, and geographic data associated with viruses. I found that [nextstrain.org/ncov/](https://nextstrain.org/ncov/) uses data from Gisaid. The visualizations include the phylogenic tree of the coronavirus (rooted to early samples of the virus from Wuhan) and shows a map of how the virus was spread and how the virus mutated over ttime. I think once I learn more about bioinformatics in the coming weeks I'll be able to conduct some new analysis that this website hasn't done yet. \n",
    "\n",
    "---\n",
    "[https://covid19.galaxyproject.org/](https://covid19.galaxyproject.org/)\n",
    "\n",
    "This goal of this site is to \"provide publicly accessible infrastructure and workflows for SARS-CoV-2 data analyses.\" Specifically, there are three different types of analysies that they feature: genomics, evolution, and cheminformatics. A lot of these methods I don't know how to use yet, but I anticipate that we'll touch on them later in the book and that I'll be able to access these workflows, implement them, and come up with some meaningful results. \n",
    "\n",
    "---\n",
    "\n",
    "TODO: Create a phylogenetic tree, don't have to analyze yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I want to download the various (complete) Coronavirus genomes. It might be useful later.\n",
    "\n",
    "From the NCBI database I downloaded a .yaml file (available [here](https://www.ncbi.nlm.nih.gov/core/assets/genbank/files/ncov-sequences.yaml)) which contained the \"accession\" ID of every sequence in their database. Using these IDs I can download each sequence using Biopython. I have to do some cleanup of the file so I can get the IDs I want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio as bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "with open(\"ncov-sequences.yaml\",\"r\") as f:\n",
    "    lines = [line.strip() for line in f.readlines() if line not in 'genbank-sequences:\\n'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices of all lines with 'accession' so we know where to slice list\n",
    "indices = [i for i, line in enumerate(lines) if '- accession' in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all sequences\n",
    "sequences = []\n",
    "for i in range(len(indices)):\n",
    "    try:\n",
    "        sequences.append(lines[indices[i]:indices[i+1]])\n",
    "    except IndexError:\n",
    "        sequences.append(lines[indices[i]:indices[i]+6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for sequences that are complete\n",
    "complete_sequences = []\n",
    "for lst in sequences:\n",
    "    for line in lst:\n",
    "        if \"gene-region: complete\" in line:\n",
    "            complete_sequences.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# use regex to grab the ids of the complete sequences\n",
    "ids = []\n",
    "for i in range(len(indices)):\n",
    "    match = re.search('accession: [A-Z]{2}[\\d]{6}',lines[indices[i]])\n",
    "    if match:\n",
    "        ids.append(match.group(0)[-8:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code was probably pretty ugly, but now we have a list of IDs that we can query the database with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "\n",
    "for _id in ids[:10]: # remove the slice notation to get all IDs. This will only grab first 10 sequences. \n",
    "    Entrez.email = \"lepopal@calpoly.edu\"  \n",
    "    filename = str(_id)+\".gbk\"\n",
    "    if not os.path.isfile(\"sequences/\" + filename):\n",
    "        # Downloading...\n",
    "        net_handle = Entrez.efetch(\n",
    "            db=\"nucleotide\", id=_id, rettype=\"gb\", retmode=\"text\"\n",
    "        )\n",
    "        out_handle = open(\"sequences/\" + filename, \"w\")\n",
    "        out_handle.write(net_handle.read())\n",
    "        out_handle.close()\n",
    "        net_handle.close()\n",
    "        print(\"Saved:\", filename)\n",
    "    else:\n",
    "        print(\"Already exists:\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the files. We can load them all into Biopython. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN938388.1\n",
      "Seq('AATGTCTATGCAGATTCATTTGTAATTAGAGGTGATGAAGTCAGACAAATCGCT...TTT', IUPACAmbiguousDNA())\n",
      "107\n",
      "MN975263.1\n",
      "Seq('TGAGTTATGAGGATCAAGATGCACTTTTCGCATATACAAAACGTAATGTCATCC...CTT', IUPACAmbiguousDNA())\n",
      "287\n",
      "MN975262.1\n",
      "Seq('ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGT...AAA', IUPACAmbiguousDNA())\n",
      "29891\n",
      "MN938389.1\n",
      "Seq('AATGTCTATGCAGATTCATTTGTAATTAGAGGTGATGAAGTCAGACAAATCGCT...TTT', IUPACAmbiguousDNA())\n",
      "107\n",
      "MN908947.3\n",
      "Seq('ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGT...AAA', IUPACAmbiguousDNA())\n",
      "29903\n",
      "MN970003.1\n",
      "Seq('TAAACACCTCATACCACTTATGTACAAAGGACTTCCTTGGAATGTAGTGCGTAT...TTG', IUPACAmbiguousDNA())\n",
      "290\n",
      "MN970004.1\n",
      "Seq('TAAACACCTCATACCACTTATGTACAAAGGACTTCCTTGGAATGTAGTGCGTAT...TTG', IUPACAmbiguousDNA())\n",
      "290\n",
      "MN938390.1\n",
      "Seq('AATGTCTATGCAGATTCATTTGTAATTAGAGGTGATGAAGTCAGACAAATCGCT...TTT', IUPACAmbiguousDNA())\n",
      "107\n",
      "MN938384.1\n",
      "Seq('CAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAATCTG...GAC', IUPACAmbiguousDNA())\n",
      "29838\n",
      "MN938385.1\n",
      "Seq('TGAGTTATGAGGATCAAGATGCACTTTTCGCATATACAAAACGTAATGTCATCC...CTT', IUPACAmbiguousDNA())\n",
      "287\n",
      "MN938387.1\n",
      "Seq('AATGTCTATGCAGATTCATTTGTAATTAGAGGTGATGAAGTCAGACAAATCGCT...TTT', IUPACAmbiguousDNA())\n",
      "107\n",
      "MN938386.1\n",
      "Seq('TGAGTTATGAGGATCAAGATGCACTTTTCGCATATACAAAACGTAATGTCATCC...CTT', IUPACAmbiguousDNA())\n",
      "287\n"
     ]
    }
   ],
   "source": [
    "files = [file for file in os.listdir(\"sequences/\") if file.endswith(\".gbk\")]\n",
    "\n",
    "for fname in files:\n",
    "    for seq_record in SeqIO.parse(\"sequences/\" + fname, \"genbank\"):\n",
    "        print(seq_record.id) # prints the ID of the sequence\n",
    "        print(repr(seq_record.seq)) # prints the nucleotide sequence\n",
    "        print(len(seq_record)) # prints the length of the nucleotide sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I think I have a good structure to start working with the data in these files. Using what we learned in Week 1, next week I want to try to find the *ori* of the virus. Also, I want to try and create a phylogenetic tree like on [nextstrain.org/ncov/](https://nextstrain.org/ncov/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
